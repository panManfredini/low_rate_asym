createdAt: "2018-05-27T11:50:22.625Z"
updatedAt: "2018-06-03T15:03:22.162Z"
type: "MARKDOWN_NOTE"
folder: "00ed0e13ebc5e5a7e218"
title: "Find dirstro of $\\hat{\\mu}$"
content: '''
  # Find dirstro of $\\hat{\\mu}$
  
  ## Starting from minimizing the likelihood
  In case the likelihood has the following form, note no nuissance parameters:
  $$
  \\mathscr{L} = Poiss(N_{obs} |  \\mu + N_b) \\cdot \\prod_{i}^{N_{obs}} \\frac{\\mu f_s(i) + N_b f_b(i)}{\\mu + N_b}
  $$
  Then we can actually find its maximum analytically by, as usual, its derivative wrt $\\mu$, $\\partial \\mathscr{L}$.
  $$
  \\partial \\mathscr{L} = e^{-\\mu -N_b} \\cdot \\bigg[ \\frac{(\\mu + N_b)^{N_{obs} - 1}) \\cdot(N_{obs} - \\mu - N_b)} {N_{obs}!} \\cdot \\prod().. + \\frac{(\\mu + N_b)^{N_{obs}}}{N_{obs}!}  \\sum_i^{N_{obs}} \\big(\\frac{(f_s -f_b)N_b}{(\\mu + N_b)^2} \\cdot \\prod_{j!=i}^{N_{obs}} \\frac{\\mu f_s(j) +N_b f_b(j)}{\\mu + N_b}  \\big) \\bigg] = 0.
  $$
  Now simplify dividing by: $\\prod_i$ ; $N_{obs}!$ ; $(\\mu +N_b)^{N_{obs} -1}$ and  what's left is:
  
  $$
  N_{obs} - \\mu - N_b + \\sum_i^{N_{obs}} \\frac{\\big( f_s - f_b \\big)N_b}{\\mu f_s +N_b f_b} = 0.
  $$
  
  #### Checks on the formula above
  Is the formula correct? Checks on the minimum (zeros of formula) VS minimum of LLR has been done for toy MC produced with SR1 "final" april_v2 models.
  The toys for the chack have:
  - $\\mu_{true}$ = 0.5 events
  - Generation = 1
  - Volume (likelihood type) = 0
  - Location usual: **"../build/RESULTS/GENtrees/apr_ER2_RG2_W2_M50_mu5\\*"**
  
  ![](/:storage/images/formula_test_example.png =350x) ![](/:storage/images/llr_scan_formula_test_example.png =350x)
  ![](/:storage/formula_test_example_zoom.png =350x)
  
  The discontinuity at -1 in first graph correspond to ~ when ($\\mu$fs +$N_b$fb) < 0. E' stato verificato che i casi di $\\mu$ negativi sono anche ben rappresentati.
  
  
  ![](/:storage/images/first_distro_mu.png)
  
  ### Taylor expansion
  One can try to tailor expand the extended term in $\\mu = \\mu_{true}$ in this particolar case below I tried with $\\mu_{true} = 0$. We start noting that one can use the fraction $f_s / f_b = x$ as a random variable of which is easy to get the distro under any hypothesis just using histograms.
  $$
  \\sum_i^{N_{obs}} \\frac{\\big( f_s - f_b \\big)N_b}{\\mu f_s +N_b f_b} = \\sum_i^{N_{obs}} \\frac{(x_i-1)N_b}{\\mu x_i + N_b}
  $$
  now let's call:
  $$
  y = \\frac{(x-1)N_b}{\\mu x + N_b}
  $$
  This function is interesting, x is defined positive and:
  ![](/:storage/images/extended_term.png =500x) ![](/:storage/low_rate_asym/images/extended_term_mu_neg.png =500x)
  I tryed to expand the function y in teylor series to try to factoraze the dependency on mu, the one gets:
  $$
  y  = \\sum_k^{inf}  \\frac{(-1)^kx^k(x-1)}{N_b^k} \\mu^k
  $$
  then one can move the sum the sum on $N_{obs}$ inside the taylor expansion and defining the symbol $f$ for brevity:
  $$
  f = \\sum_i^{N_{obs}} x_i ;  ~ ~~ ~f^2= \\sum_i^{N_{obs}} x_i^2 ~ .....~ ~ ~ f^k = \\sum_i^{N_{obs}} x_i^k
  $$
  then the formula can be expressed factorizing the $\\mu$ component as:
  $$
  N_{obs} - \\mu - N_b + \\sum_k^{inf} (-\\mu)^k \\frac{(f^{k+1} - f^k)}{N_b^k} =0
  $$
  is very easy to compute the distros of the $f^k$ so this would be great if one could stop at let's say the first or second term of expansion, but seems like even up to the fifth term I could not get a reasonable $\\mu$ distribution...
  
  ![](/:storage/images/extended_term_approx_05.png =600x)![](/:storage/images/extended_term_approx_1.png =600x)
  ![](/:storage/images/extended_term_approx_2.png =600x)![](/:storage/images/extended_term_approx_3.png =600x)
  This is trying to approximate the extended term for mu = 0.5, 1, 2, 3 respectively in the picture above.
  The code for running the approximation is in **XEPHYR_PKG/low_rate_asym/ex_term_approx_attemp.C**
  
  
  ### Extended term distro
  We start with the distro of $x = f_s / f_b$ then we can generate (via MC toys) the distro of sums of it.
  ![](/:storage/images/fs_over_fb_distro.png =500x)
  the above is generated by dividing the two histos (fs and fb), going over all bins and filling a new histo with X weighted by the bkg pdf. 
  Find the code in **XEPHYR_PKG/low_rate_asym/exTerm_vs_mu.C**
  
  ![](/:storage/images/extended_term_distro.png =800x)
  
  
  #### Summary provisorio
  - ho testato che riesco ad ottenere la distribuzione di mu negativi che sembra corretta
  - usare Fs/Fb sembra un inizio promettente, se ne possono trovare le distro molto facilmente
  - Studiare the extended_term per trovare approx:
    - Distro extended term (ex_term)
    - Dipendenza of extended term on mu, plot distro ex_term for different values of mu
    - Determinare un'approx valida per la somma di random variable di cui conosci la distro
    - Provare con sviluppo in serie del ex_term
  - Verificare che la distro di mu ottenuta con **"distro_mu_hat_attemp.C"** rispecchia quella ottenuta facend il fit in modo classico
  - Tentare lo stesso gioco con un'altra likelihood "the poisson product"
  - Try to see if one can identify, break the extended term in components that have to do with some sort of population
  
  
'''
tags: []
isStarred: false
isTrashed: false
